{"cells":[{"cell_type":"markdown","source":["# Notebook Initialization"],"metadata":{"id":"B6wgI_pJq5by"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qzvj6R9De1TQ"},"outputs":[],"source":["from google.colab import drive\n","from tqdm.auto import tqdm\n","import os\n","import shutil\n","import json\n","import torch\n","import matplotlib.pyplot as plt\n","\n","drive.mount('/content/drive')\n","DRIVE_ROOT_DIR_PATH = 'MyDrive/nesy'\n","DRIVE_DATASETS_DIR = 'prepared_datasets'"]},{"cell_type":"code","source":["shutil.copy(f'/content/drive/{DRIVE_ROOT_DIR_PATH}/visudo_scripts.zip', '/content/')\n","shutil.unpack_archive('/content/visudo_scripts.zip', 'visudo_scripts', 'zip')\n","os.remove('/content/visudo_scripts.zip')\n","print('The `visudo` scripts were unpacked.')"],"metadata":{"id":"9ow6e9QLNkmV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Collection"],"metadata":{"id":"GAGjvKi5q8l4"}},{"cell_type":"markdown","source":["## Constants"],"metadata":{"id":"jYtQBnREvS34"}},{"cell_type":"code","source":["SOURCE_MAP = {\n","    'mnist': lambda label: int(str(label).split('_')[-1]),\n","    'emnist': lambda label: int(str(label).split('_')[-1]) - 10,\n","    'kmnist': lambda label: int(str(label).split('_')[-1]),\n","    'fmnist': lambda label: int(str(label).split('_')[-1])\n","}\n","BOARD_DIM_LIST = [4, 9]\n","SPLIT_LIST = list(split + 1 for split in range(11))"],"metadata":{"id":"BDW8vYG4QQgZ","executionInfo":{"status":"ok","timestamp":1758531507839,"user_tz":-120,"elapsed":4,"user":{"displayName":"Homayoun Afshari","userId":"15693660695795650579"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Tools"],"metadata":{"id":"FUbtxXCGvVje"}},{"cell_type":"code","source":["def collect(source_name:str, board_dim:int, split:int, verbose:bool) -> None:\n","\n","    # Initialization\n","    if source_name not in SOURCE_MAP:\n","        raise ValueError(f'Unknown source: {source_name}')\n","    if board_dim not in BOARD_DIM_LIST:\n","        raise ValueError(f'Unknown board dimension: {board_dim}')\n","    if split not in SPLIT_LIST:\n","        raise ValueError(f'Unknown split: {split}')\n","    if verbose:\n","        print(f'Source: {source_name}, Board Dimension: {board_dim}, Split: {split}')\n","    dataset_name = f'{source_name}_{board_dim}x{board_dim}_split_{split:02}'\n","    output_dir_path = f'/content/data/{dataset_name}'\n","\n","    # Download\n","    if verbose:\n","        print('  Downloading...')\n","    if not os.path.exists('/content/data/'):\n","        os.makedirs('/content/data/')\n","    !python /content/visudo_scripts/generate-split.py --dataset {source_name} --dimension {board_dim} --split {split} --out-dir {output_dir_path} > /dev/null 2>&1\n","\n","    # Investigation\n","    if verbose:\n","        print('  Investigating...')\n","    current_dir_path = output_dir_path\n","    while True:\n","        child_list = os.listdir(current_dir_path)\n","        if len(child_list) == 1 and child_list[0].endswith(''):\n","            current_dir_path = os.path.join(current_dir_path, child_list[0])\n","            continue\n","        break\n","\n","    # Processing\n","    if verbose:\n","        print('  Processing...')\n","    data_dict = {\n","        'train': dict[str, torch.Tensor](),\n","        'val': dict[str, torch.Tensor](),\n","        'test': dict[str, torch.Tensor]()\n","    }\n","    for alias, subset_name in zip(['train', 'valid', 'test'], data_dict):\n","        with open(os.path.join(current_dir_path, f'{alias}_puzzle_pixels.txt'), 'r') as text_file:\n","            symbols = torch.tensor([json.loads('[' + line.replace('\\t', ',') + ']') for line in text_file.readlines()])\n","            data_dict[subset_name]['symbols'] = (symbols.reshape(200, board_dim, board_dim, 28, 28) * 255).to(torch.uint8)\n","        with open(os.path.join(current_dir_path, f'{alias}_cell_labels.txt'), 'r') as text_file:\n","            digits = torch.tensor([[SOURCE_MAP[source_name](label) for label in line.strip().split('\\t')] for line in text_file.readlines()])\n","            data_dict[subset_name]['digits'] = digits.reshape(200, board_dim, board_dim).to(torch.uint8)\n","        with open(os.path.join(current_dir_path, f'{alias}_puzzle_labels.txt'), 'r') as text_file:\n","            labels = torch.tensor([int(line.strip().split('\\t')[0]) for line in text_file.readlines()])\n","        data_dict[subset_name]['labels'] = labels.to(torch.bool)\n","\n","    # Storage\n","    if verbose:\n","        print('  Storing...')\n","    dataset_path = f'/content/data/{dataset_name}.pt'\n","    if os.path.exists(dataset_path):\n","        os.remove(dataset_path)\n","    torch.save(data_dict, dataset_path)\n","\n","    # Cache Removal\n","    if verbose:\n","        print('  Removing Cache...')\n","    shutil.rmtree(output_dir_path)\n","\n","\n","def visualize(source_name:str, board_dim:int, split:int, n_boards:int) -> None:\n","\n","    # Initialization\n","    dataset_path = f'/content/data/{source_name}_{board_dim}x{board_dim}_split_{split:02}.pt'\n","    if not os.path.exists(dataset_path):\n","        raise ValueError(f'Dataset not found: {dataset_path}')\n","    data_dict:dict[str, dict[str, torch.Tensor]] = torch.load(dataset_path)\n","\n","    # Visualization\n","    subset = ['train', 'val', 'test'][torch.randint(0, 3, (1,)).item()]\n","    symbols = data_dict[subset]['symbols']\n","    digits = data_dict[subset]['digits']\n","    labels = data_dict[subset]['labels']\n","    for l in torch.randperm(symbols.shape[0])[:n_boards]:\n","        fig, axs = plt.subplots(nrows=board_dim, ncols=board_dim, figsize=(3, 3))\n","        fig.suptitle(f'Board `{l}` of Subset `{subset}` with Label `{labels[l]}`', fontsize=8)\n","        for i in range(board_dim):\n","            for j in range(board_dim):\n","                ax:plt.Axes = axs[i, j]\n","                ax.imshow(symbols[l, i, j, :, :], cmap='gray')\n","                ax.set_title(f'{digits[l, i, j]}', fontsize=6)\n","                ax.axis('off')\n","        fig.tight_layout()"],"metadata":{"id":"q6pOuZQ7GnNt","executionInfo":{"status":"ok","timestamp":1758531517767,"user_tz":-120,"elapsed":6,"user":{"displayName":"Homayoun Afshari","userId":"15693660695795650579"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Collection"],"metadata":{"id":"Ez4S-0p3TIIL"}},{"cell_type":"code","source":["collect(\n","    source_name='mnist',\n","    board_dim=4,\n","    split=2,\n","    verbose=True\n",")"],"metadata":{"id":"O7xpzTX3Ql1g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize(\n","    source_name='mnist',\n","    board_dim=4,\n","    split=2,\n","    n_boards=1\n",")"],"metadata":{"id":"PTPoeonRSa7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Transfering to Drive"],"metadata":{"id":"7hjetrDIvYT2"}},{"cell_type":"code","source":["for file_name in os.listdir('/content/data/'):\n","    if file_name.endswith('.pt'):\n","        drive_dataset_dir_path = f'/content/drive/{DRIVE_ROOT_DIR_PATH}/{DRIVE_DATASETS_DIR}/'\n","        if not os.path.exists(drive_dataset_dir_path):\n","            os.makedirs(drive_dataset_dir_path)\n","        shutil.copy(f'/content/data/{file_name}', f'/content/drive/{DRIVE_ROOT_DIR_PATH}/{DRIVE_DATASETS_DIR}/{file_name}')"],"metadata":{"id":"e-ypNrsVuISn","executionInfo":{"status":"ok","timestamp":1758531617278,"user_tz":-120,"elapsed":693,"user":{"displayName":"Homayoun Afshari","userId":"15693660695795650579"}}},"execution_count":8,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}